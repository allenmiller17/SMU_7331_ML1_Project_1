{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shBxlqWhtBMq"
   },
   "source": [
    "# DS-7331 Machine Learning Project 2\n",
    "## Airbnb Price Data - Logistic and SVM\n",
    "### Allen Miller, Ana Glaser, Jake Harrison, Lola Awodipe\n",
    "\n",
    "https://nbviewer.jupyter.org/github/allenmiller17/SMU_7331_ML1_Project_1/blob/main/Mini_Project_Final.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "0UVfzQcEtBMv"
   },
   "outputs": [],
   "source": [
    "#loading libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "2APcUIoQtPIU"
   },
   "outputs": [],
   "source": [
    "#setting path and loading data\n",
    "pdata = pd.read_csv(\"airbnb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UmfOcVQtBMx"
   },
   "source": [
    "### **Business Understanding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBhbwwXPD4YP"
   },
   "source": [
    "\n",
    "For our project, we decided to use AirBnb data from six major cities in the United States from kaggle.com. Our objective is to classify the type of property based on the data attributes like city, number of reviews, bathrooms, bedrooms and number of people it accommodates. To assess the effectiveness of our classification, we will look at the accuracy, precision, recall and evaluate the confusion matrix results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KklHSSoqyX8F"
   },
   "source": [
    "### **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining the Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7nEeG-gtBMw",
    "outputId": "22fa620c-c35a-41bb-acef-8db2f5b96eb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74111 entries, 0 to 74110\n",
      "Data columns (total 26 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      74111 non-null  int64  \n",
      " 1   log_price               74111 non-null  float64\n",
      " 2   property_type           74111 non-null  object \n",
      " 3   room_type               74111 non-null  object \n",
      " 4   accommodates            74111 non-null  int64  \n",
      " 5   bathrooms               73911 non-null  float64\n",
      " 6   bed_type                74111 non-null  object \n",
      " 7   cancellation_policy     74111 non-null  object \n",
      " 8   cleaning_fee            74111 non-null  bool   \n",
      " 9   city                    74111 non-null  object \n",
      " 10  description             74111 non-null  object \n",
      " 11  first_review            58247 non-null  object \n",
      " 12  host_has_profile_pic    73923 non-null  object \n",
      " 13  host_identity_verified  73923 non-null  object \n",
      " 14  host_response_rate      55812 non-null  object \n",
      " 15  host_since              73923 non-null  object \n",
      " 16  instant_bookable        74111 non-null  object \n",
      " 17  last_review             58284 non-null  object \n",
      " 18  latitude                74111 non-null  float64\n",
      " 19  longitude               74111 non-null  float64\n",
      " 20  neighbourhood           67239 non-null  object \n",
      " 21  number_of_reviews       74111 non-null  int64  \n",
      " 22  review_scores_rating    57389 non-null  float64\n",
      " 23  zipcode                 73145 non-null  object \n",
      " 24  bedrooms                74020 non-null  float64\n",
      " 25  beds                    73980 non-null  float64\n",
      "dtypes: bool(1), float64(7), int64(3), object(15)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#importing the data and exploring the attributes\n",
    "#pdata = pd.read_csv(\"airbnb.csv\")\n",
    "pdata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lYHCMFNyuAb"
   },
   "source": [
    "##### Preparing Class Variables\n",
    "\n",
    "Based on our understanding of the data structure and the assumptions required for this type of classification task, we prepared and transformed the data as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jp1K4Vxl-HO8"
   },
   "source": [
    "Due to feedback received from our last submission and implementing the CRISP methodology we decided to re-evaluate  the outliers and structure of the dataset.  Four features stood out to us as being heavily skewed, so we took a deeper dive into those data sets and evaluates how to approach their outliers. \n",
    "\n",
    "The number of reviews feature showed data that was heavily skewed to the left. Running the models with and without the outliers, we concluded that these outliers didn't provide a lot of predictive power, but the feature overall did. This led us to take all the outliers that fell below the 1st quartile, and bring them up ot the lowest whisker. Although it did not normally distribute the observations it did significantly reduce the level of skewness in the data from 3 to 1.\n",
    "\n",
    "This process was repeated for the review scores rating, and beds features with a similar result in reducing the skewness of the data.  Since Logistic regression does not require the data to be normally distributed, we proceeded with the analysis.\n",
    "\n",
    "Finally after exploring the bedrooms, accommodates and bathrooms outliers, we felt it best to leave these outliers untouched, since these attributes are more relevant when determining what type of property it is. We felt that they still held predictive power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHuLgiOI-HO8"
   },
   "source": [
    "##### Attributes and Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmdIm67NNA29"
   },
   "source": [
    "Because normality is not an assumption for Logistic Regression we weren't worried about having a normal distribution for our feature observations, so we chose not to transform any of these variables.\n",
    "\n",
    "The attribute of neighborhood made our data very sparse and it increased run time dramatically, when we tested the models with and without it, we only lost 3% accuracy points, so the cost benefit of run time vs model performance seemed like a fair trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "0DyQP_DXQEYC"
   },
   "outputs": [],
   "source": [
    "#removing outliers to reduce skewness of data \n",
    "z = pdata[pdata['number_of_reviews']> 100]\n",
    "for i in list (z[z['number_of_reviews']> 100].index):\n",
    "    pdata.loc[i,'number_of_reviews'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "6YwlnlAWQYna"
   },
   "outputs": [],
   "source": [
    "y = pdata[pdata['review_scores_rating']< 80]\n",
    "for i in list (y[y['review_scores_rating']< 80].index):\n",
    "    pdata.loc[i,'review_scores_rating'] = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "gPzCuBe3RT30"
   },
   "outputs": [],
   "source": [
    "x = pdata[pdata['beds']> 5]\n",
    "for i in list (x[x['beds']> 5].index):\n",
    "    pdata.loc[i,'beds'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggpi4uHVncaL",
    "outputId": "f7859039-56f0-43c3-cad7-216defba9702"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     -0.260616\n",
       "log_price               0.514695\n",
       "accommodates            2.231561\n",
       "bathrooms               3.691453\n",
       "cleaning_fee           -1.059603\n",
       "latitude               -0.534766\n",
       "longitude              -0.407100\n",
       "number_of_reviews       1.841134\n",
       "review_scores_rating   -1.143345\n",
       "bedrooms                1.989849\n",
       "beds                    1.692681\n",
       "dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating data for skewness after outlier transformation\n",
    "pdata.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "qr9f9CXftBMx"
   },
   "outputs": [],
   "source": [
    "#dropping records with excess blank values, still had over 64k records to evaluate\n",
    "pdata_cls = pdata.dropna()\n",
    "#imputing missing numerical data by using the median, removing records with missing categorical values\n",
    "pdata_reg = pdata.fillna(pdata.median())\n",
    "pdata_reg = pdata_reg.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     -0.255823\n",
       "log_price               0.377120\n",
       "accommodates            2.119839\n",
       "bathrooms               3.705744\n",
       "cleaning_fee           -1.701312\n",
       "latitude               -0.649299\n",
       "longitude              -0.502707\n",
       "number_of_reviews       1.268297\n",
       "review_scores_rating   -1.155152\n",
       "bedrooms                1.874469\n",
       "beds                    1.539853\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating data for skewness after outlier transformation after splitting data based on task\n",
    "pdata_cls.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     -0.254923\n",
       "log_price               0.381099\n",
       "accommodates            2.129464\n",
       "bathrooms               3.716646\n",
       "cleaning_fee           -1.678508\n",
       "latitude               -0.650879\n",
       "longitude              -0.504401\n",
       "number_of_reviews       1.276446\n",
       "review_scores_rating   -1.162697\n",
       "bedrooms                1.877781\n",
       "beds                    1.546403\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata_reg.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oovA0q2v-HO_"
   },
   "source": [
    "##### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IL3Kv6iF-HO_"
   },
   "source": [
    "To assist in predicting the property type of an Airbnb we decided to make a couple of changes to the features that could increase the predictability. \n",
    "\n",
    "We first collapsed the property type feature to only contain two distinct values, making this a binary classification problem. A property type could only be classified as Apartment or Other. This eliminated the smaller sub-types of a property such as, Loft, Condo, House, etc. We chose Apartment due to the large amounts of observations that were present in the data set and saw an increase in our accuracy (found at the end of this report)\n",
    "\n",
    "Second we decided to remove the longitude and latitude variables and replace them with a variable called region. This variable split the United States in half and classified the observation as either East or West. This increased the performance of our models and allowed us to reduce the number of predictors included in the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "od-fD77wtBMx"
   },
   "outputs": [],
   "source": [
    "#transforming the property type to a binary classification\n",
    "value_list = [\"Apartment\"]\n",
    "boolean_series = ~pdata_cls.property_type.isin(value_list)\n",
    "filtered_df = pdata_cls[boolean_series]\n",
    "\n",
    "filtered_df.head(100)\n",
    "\n",
    "for i in list (filtered_df.index):\n",
    "    pdata_cls.loc[i,'property_type'] = \"other\"\n",
    "\n",
    "#transforming the longitude and latitude variables to East / West\n",
    "pdata_cls[\"region\"] = pd.cut(pdata_cls.longitude,[-200,-100,0],2,labels=[\"West\",\"East\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "4BA1AxqKtBMy",
    "outputId": "520e7a65-1102-4e71-9870-0e0922fd6bcd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>log_price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>last_review</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6304928</td>\n",
       "      <td>5.129899</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>...</td>\n",
       "      <td>9/23/2017</td>\n",
       "      <td>40.766115</td>\n",
       "      <td>-73.989040</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7919400</td>\n",
       "      <td>4.976734</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>...</td>\n",
       "      <td>9/14/2017</td>\n",
       "      <td>40.808110</td>\n",
       "      <td>-73.943756</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>10</td>\n",
       "      <td>92.0</td>\n",
       "      <td>10027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3808709</td>\n",
       "      <td>4.744932</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>DC</td>\n",
       "      <td>...</td>\n",
       "      <td>1/22/2017</td>\n",
       "      <td>38.925627</td>\n",
       "      <td>-77.034596</td>\n",
       "      <td>Columbia Heights</td>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>20009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12422935</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>SF</td>\n",
       "      <td>...</td>\n",
       "      <td>9/5/2017</td>\n",
       "      <td>37.753164</td>\n",
       "      <td>-122.429526</td>\n",
       "      <td>Noe Valley</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13971273</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>other</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>...</td>\n",
       "      <td>4/12/2017</td>\n",
       "      <td>34.046737</td>\n",
       "      <td>-118.260439</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>9</td>\n",
       "      <td>93.0</td>\n",
       "      <td>90015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  log_price property_type        room_type  accommodates  \\\n",
       "1   6304928   5.129899     Apartment  Entire home/apt             7   \n",
       "2   7919400   4.976734     Apartment  Entire home/apt             5   \n",
       "4   3808709   4.744932     Apartment  Entire home/apt             2   \n",
       "5  12422935   4.442651     Apartment     Private room             2   \n",
       "7  13971273   4.787492         other  Entire home/apt             2   \n",
       "\n",
       "   bathrooms  bed_type cancellation_policy  cleaning_fee city  ...  \\\n",
       "1        1.0  Real Bed              strict          True  NYC  ...   \n",
       "2        1.0  Real Bed            moderate          True  NYC  ...   \n",
       "4        1.0  Real Bed            moderate          True   DC  ...   \n",
       "5        1.0  Real Bed              strict          True   SF  ...   \n",
       "7        1.0  Real Bed            moderate          True   LA  ...   \n",
       "\n",
       "  last_review   latitude   longitude     neighbourhood number_of_reviews  \\\n",
       "1   9/23/2017  40.766115  -73.989040    Hell's Kitchen                 6   \n",
       "2   9/14/2017  40.808110  -73.943756            Harlem                10   \n",
       "4   1/22/2017  38.925627  -77.034596  Columbia Heights                 4   \n",
       "5    9/5/2017  37.753164 -122.429526        Noe Valley                 3   \n",
       "7   4/12/2017  34.046737 -118.260439          Downtown                 9   \n",
       "\n",
       "  review_scores_rating zipcode bedrooms  beds  region  \n",
       "1                 93.0   10019      3.0   3.0    East  \n",
       "2                 92.0   10027      1.0   3.0    East  \n",
       "4                 80.0   20009      0.0   1.0    East  \n",
       "5                100.0   94131      1.0   1.0    West  \n",
       "7                 93.0   90015      1.0   1.0    West  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating the data after transformation\n",
    "pdata_cls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WsSYgNL-HPA"
   },
   "source": [
    "##### Encoding binary variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THgNLoL8-HPA"
   },
   "source": [
    "To help our model we encoded all of the boolean features that were originally stored as character fields to reflect actual boolean type variables and reflected true values with a 1 and false values with a 0.\n",
    "\n",
    "We also encoded our response variable to 1 vs 2 to reflect Apartment vs Other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "YjFDyE46tBMz",
    "outputId": "21b4a8d4-ef5d-4b07-e401-c1a379070959"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>log_price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>last_review</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6304928</td>\n",
       "      <td>5.129899</td>\n",
       "      <td>1</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>1</td>\n",
       "      <td>NYC</td>\n",
       "      <td>...</td>\n",
       "      <td>9/23/2017</td>\n",
       "      <td>40.766115</td>\n",
       "      <td>-73.989040</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7919400</td>\n",
       "      <td>4.976734</td>\n",
       "      <td>1</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1</td>\n",
       "      <td>NYC</td>\n",
       "      <td>...</td>\n",
       "      <td>9/14/2017</td>\n",
       "      <td>40.808110</td>\n",
       "      <td>-73.943756</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>10</td>\n",
       "      <td>92.0</td>\n",
       "      <td>10027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3808709</td>\n",
       "      <td>4.744932</td>\n",
       "      <td>1</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1</td>\n",
       "      <td>DC</td>\n",
       "      <td>...</td>\n",
       "      <td>1/22/2017</td>\n",
       "      <td>38.925627</td>\n",
       "      <td>-77.034596</td>\n",
       "      <td>Columbia Heights</td>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>20009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12422935</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>1</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>1</td>\n",
       "      <td>SF</td>\n",
       "      <td>...</td>\n",
       "      <td>9/5/2017</td>\n",
       "      <td>37.753164</td>\n",
       "      <td>-122.429526</td>\n",
       "      <td>Noe Valley</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13971273</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>2</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1</td>\n",
       "      <td>LA</td>\n",
       "      <td>...</td>\n",
       "      <td>4/12/2017</td>\n",
       "      <td>34.046737</td>\n",
       "      <td>-118.260439</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>9</td>\n",
       "      <td>93.0</td>\n",
       "      <td>90015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  log_price  property_type        room_type  accommodates  \\\n",
       "1   6304928   5.129899              1  Entire home/apt             7   \n",
       "2   7919400   4.976734              1  Entire home/apt             5   \n",
       "4   3808709   4.744932              1  Entire home/apt             2   \n",
       "5  12422935   4.442651              1     Private room             2   \n",
       "7  13971273   4.787492              2  Entire home/apt             2   \n",
       "\n",
       "   bathrooms  bed_type cancellation_policy  cleaning_fee city  ...  \\\n",
       "1        1.0  Real Bed              strict             1  NYC  ...   \n",
       "2        1.0  Real Bed            moderate             1  NYC  ...   \n",
       "4        1.0  Real Bed            moderate             1   DC  ...   \n",
       "5        1.0  Real Bed              strict             1   SF  ...   \n",
       "7        1.0  Real Bed            moderate             1   LA  ...   \n",
       "\n",
       "  last_review   latitude   longitude     neighbourhood number_of_reviews  \\\n",
       "1   9/23/2017  40.766115  -73.989040    Hell's Kitchen                 6   \n",
       "2   9/14/2017  40.808110  -73.943756            Harlem                10   \n",
       "4   1/22/2017  38.925627  -77.034596  Columbia Heights                 4   \n",
       "5    9/5/2017  37.753164 -122.429526        Noe Valley                 3   \n",
       "7   4/12/2017  34.046737 -118.260439          Downtown                 9   \n",
       "\n",
       "  review_scores_rating  zipcode bedrooms  beds  region  \n",
       "1                 93.0    10019      3.0   3.0    East  \n",
       "2                 92.0    10027      1.0   3.0    East  \n",
       "4                 80.0    20009      0.0   1.0    East  \n",
       "5                100.0    94131      1.0   1.0    West  \n",
       "7                 93.0    90015      1.0   1.0    West  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding boolean and categorical variables\n",
    "replaceStruct = {\n",
    "                \"cleaning_fee\":     {True: 1, False: 0},\n",
    "                \"instant_bookable\":     {\"t\": 1, \"f\": 0},\n",
    "                \"host_identity_verified\":     {\"t\": 1, \"f\": 0},\n",
    "                \"property_type\":     {\"Apartment\": 1, \"other\": 2},\n",
    "                    }\n",
    "\n",
    "pdata_cls=pdata_cls.replace(replaceStruct)\n",
    "pdata_cls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>log_price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>last_review</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6304928</td>\n",
       "      <td>5.129899</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>1</td>\n",
       "      <td>NYC</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9/23/2017</td>\n",
       "      <td>40.766115</td>\n",
       "      <td>-73.989040</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7919400</td>\n",
       "      <td>4.976734</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1</td>\n",
       "      <td>NYC</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9/14/2017</td>\n",
       "      <td>40.808110</td>\n",
       "      <td>-73.943756</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>10</td>\n",
       "      <td>92.0</td>\n",
       "      <td>10027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3808709</td>\n",
       "      <td>4.744932</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1</td>\n",
       "      <td>DC</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1/22/2017</td>\n",
       "      <td>38.925627</td>\n",
       "      <td>-77.034596</td>\n",
       "      <td>Columbia Heights</td>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>20009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12422935</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>1</td>\n",
       "      <td>SF</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9/5/2017</td>\n",
       "      <td>37.753164</td>\n",
       "      <td>-122.429526</td>\n",
       "      <td>Noe Valley</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13971273</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1</td>\n",
       "      <td>LA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4/12/2017</td>\n",
       "      <td>34.046737</td>\n",
       "      <td>-118.260439</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>9</td>\n",
       "      <td>93.0</td>\n",
       "      <td>90015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  log_price property_type        room_type  accommodates  \\\n",
       "1   6304928   5.129899     Apartment  Entire home/apt             7   \n",
       "2   7919400   4.976734     Apartment  Entire home/apt             5   \n",
       "4   3808709   4.744932     Apartment  Entire home/apt             2   \n",
       "5  12422935   4.442651     Apartment     Private room             2   \n",
       "7  13971273   4.787492   Condominium  Entire home/apt             2   \n",
       "\n",
       "   bathrooms  bed_type cancellation_policy  cleaning_fee city  ...  \\\n",
       "1        1.0  Real Bed              strict             1  NYC  ...   \n",
       "2        1.0  Real Bed            moderate             1  NYC  ...   \n",
       "4        1.0  Real Bed            moderate             1   DC  ...   \n",
       "5        1.0  Real Bed              strict             1   SF  ...   \n",
       "7        1.0  Real Bed            moderate             1   LA  ...   \n",
       "\n",
       "  instant_bookable last_review   latitude   longitude     neighbourhood  \\\n",
       "1                1   9/23/2017  40.766115  -73.989040    Hell's Kitchen   \n",
       "2                1   9/14/2017  40.808110  -73.943756            Harlem   \n",
       "4                1   1/22/2017  38.925627  -77.034596  Columbia Heights   \n",
       "5                1    9/5/2017  37.753164 -122.429526        Noe Valley   \n",
       "7                0   4/12/2017  34.046737 -118.260439          Downtown   \n",
       "\n",
       "  number_of_reviews  review_scores_rating zipcode  bedrooms  beds  \n",
       "1                 6                  93.0   10019       3.0   3.0  \n",
       "2                10                  92.0   10027       1.0   3.0  \n",
       "4                 4                  80.0   20009       0.0   1.0  \n",
       "5                 3                 100.0   94131       1.0   1.0  \n",
       "7                 9                  93.0   90015       1.0   1.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaceStruct = {\n",
    "                \"cleaning_fee\":     {True: 1, False: 0},\n",
    "                \"instant_bookable\":     {\"t\": 1, \"f\": 0},\n",
    "                \"host_identity_verified\":     {\"t\": 1, \"f\": 0},\n",
    "                    }\n",
    "pdata_reg=pdata_reg.replace(replaceStruct)\n",
    "pdata_reg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtTGZpfL-HPB"
   },
   "source": [
    "##### One-Hot Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmA_HBUX-HPB"
   },
   "source": [
    "We proceeded to one hot encode the categorical variables that we were going to leave in our models. This created a reference variable (0) and allows us to interpret the coefficients of the variables easier.\n",
    "\n",
    "We also evaluated the number of unique values found in the categorical variables, since hot-encoding the neighborhood attribute, which seemed useful in predicting property type in some cases, had 590 distinct values.  This made the model run time very slow and only gained a modest amount of accuracy.\n",
    "\n",
    "We then dropped all of the other columns that would not be used in the proceeding models, like property descriptions, and those that resulted in a 0.0 coefficient value, lacking predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJvXCpeXtBMz",
    "outputId": "bac6197b-8f61-41ba-f0a2-427b4fcc0826"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        42775\n",
       "log_price                   643\n",
       "property_type                 2\n",
       "room_type                     3\n",
       "accommodates                 16\n",
       "bathrooms                    17\n",
       "bed_type                      5\n",
       "cancellation_policy           5\n",
       "cleaning_fee                  2\n",
       "city                          6\n",
       "description               42424\n",
       "first_review               2489\n",
       "host_has_profile_pic          2\n",
       "host_identity_verified        2\n",
       "host_response_rate           77\n",
       "host_since                 3000\n",
       "instant_bookable              2\n",
       "last_review                1100\n",
       "latitude                  42758\n",
       "longitude                 42734\n",
       "neighbourhood               590\n",
       "number_of_reviews           100\n",
       "review_scores_rating         21\n",
       "zipcode                     577\n",
       "bedrooms                     11\n",
       "beds                          6\n",
       "region                        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating categorical value count for one-hot-encoding\n",
    "pdata_cls.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "_r7bp7i1tBM0",
    "outputId": "4de4eef3-6837-4758-ded7-b4c90ce33fb3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>...</th>\n",
       "      <th>city_Chicago</th>\n",
       "      <th>city_DC</th>\n",
       "      <th>city_LA</th>\n",
       "      <th>city_NYC</th>\n",
       "      <th>city_SF</th>\n",
       "      <th>cancellation_policy_moderate</th>\n",
       "      <th>cancellation_policy_strict</th>\n",
       "      <th>cancellation_policy_super_strict_30</th>\n",
       "      <th>cancellation_policy_super_strict_60</th>\n",
       "      <th>region_East</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.129899</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.976734</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.744932</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.442651</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.787492</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.787492</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.605170</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.010635</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.298317</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.595120</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    log_price  property_type  accommodates  bathrooms  host_identity_verified  \\\n",
       "1    5.129899              1             7        1.0                       0   \n",
       "2    4.976734              1             5        1.0                       1   \n",
       "4    4.744932              1             2        1.0                       1   \n",
       "5    4.442651              1             2        1.0                       1   \n",
       "7    4.787492              2             2        1.0                       1   \n",
       "8    4.787492              2             2        1.0                       0   \n",
       "10   4.605170              1             2        1.0                       1   \n",
       "11   5.010635              2             4        1.5                       1   \n",
       "13   5.298317              1             6        1.5                       1   \n",
       "17   4.595120              2             2        2.0                       1   \n",
       "\n",
       "    instant_bookable  number_of_reviews  review_scores_rating  bedrooms  beds  \\\n",
       "1                  1                  6                  93.0       3.0   3.0   \n",
       "2                  1                 10                  92.0       1.0   3.0   \n",
       "4                  1                  4                  80.0       0.0   1.0   \n",
       "5                  1                  3                 100.0       1.0   1.0   \n",
       "7                  0                  9                  93.0       1.0   1.0   \n",
       "8                  0                100                  99.0       1.0   1.0   \n",
       "10                 0                 82                  93.0       1.0   1.0   \n",
       "11                 0                 29                  97.0       2.0   2.0   \n",
       "13                 1                 13                  89.0       2.0   3.0   \n",
       "17                 0                 12                  88.0       1.0   1.0   \n",
       "\n",
       "    ...  city_Chicago  city_DC  city_LA  city_NYC  city_SF  \\\n",
       "1   ...             0        0        0         1        0   \n",
       "2   ...             0        0        0         1        0   \n",
       "4   ...             0        1        0         0        0   \n",
       "5   ...             0        0        0         0        1   \n",
       "7   ...             0        0        1         0        0   \n",
       "8   ...             0        0        0         0        1   \n",
       "10  ...             0        0        0         1        0   \n",
       "11  ...             0        0        1         0        0   \n",
       "13  ...             0        1        0         0        0   \n",
       "17  ...             0        0        0         0        0   \n",
       "\n",
       "    cancellation_policy_moderate  cancellation_policy_strict  \\\n",
       "1                              0                           1   \n",
       "2                              1                           0   \n",
       "4                              1                           0   \n",
       "5                              0                           1   \n",
       "7                              1                           0   \n",
       "8                              1                           0   \n",
       "10                             0                           1   \n",
       "11                             0                           1   \n",
       "13                             0                           1   \n",
       "17                             0                           1   \n",
       "\n",
       "    cancellation_policy_super_strict_30  cancellation_policy_super_strict_60  \\\n",
       "1                                     0                                    0   \n",
       "2                                     0                                    0   \n",
       "4                                     0                                    0   \n",
       "5                                     0                                    0   \n",
       "7                                     0                                    0   \n",
       "8                                     0                                    0   \n",
       "10                                    0                                    0   \n",
       "11                                    0                                    0   \n",
       "13                                    0                                    0   \n",
       "17                                    0                                    0   \n",
       "\n",
       "    region_East  \n",
       "1             1  \n",
       "2             1  \n",
       "4             1  \n",
       "5             0  \n",
       "7             0  \n",
       "8             0  \n",
       "10            1  \n",
       "11            0  \n",
       "13            1  \n",
       "17            1  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding categorical variables and dropping columns that are not used\n",
    "oneHotCols=[\"room_type\",\"bed_type\",\"city\",\"cancellation_policy\",\"region\"]\n",
    "pdata_cls.drop(['description','host_response_rate','first_review','host_since','last_review','zipcode','id','latitude','longitude','neighbourhood','cleaning_fee','host_has_profile_pic'], axis=1, inplace=True)\n",
    "pdata_cls=pd.get_dummies(pdata_cls, columns=oneHotCols,drop_first=True)\n",
    "pdata_cls.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_price</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>property_type_Serviced apartment</th>\n",
       "      <th>property_type_Tent</th>\n",
       "      <th>property_type_Timeshare</th>\n",
       "      <th>property_type_Tipi</th>\n",
       "      <th>property_type_Townhouse</th>\n",
       "      <th>property_type_Train</th>\n",
       "      <th>property_type_Treehouse</th>\n",
       "      <th>property_type_Vacation home</th>\n",
       "      <th>property_type_Villa</th>\n",
       "      <th>property_type_Yurt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.129899</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.766115</td>\n",
       "      <td>-73.989040</td>\n",
       "      <td>6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.976734</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.808110</td>\n",
       "      <td>-73.943756</td>\n",
       "      <td>10</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.744932</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.925627</td>\n",
       "      <td>-77.034596</td>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.442651</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.753164</td>\n",
       "      <td>-122.429526</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.787492</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34.046737</td>\n",
       "      <td>-118.260439</td>\n",
       "      <td>9</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.787492</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.781128</td>\n",
       "      <td>-122.501095</td>\n",
       "      <td>100</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.605170</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.723883</td>\n",
       "      <td>-73.983880</td>\n",
       "      <td>82</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.010635</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.875862</td>\n",
       "      <td>-118.403293</td>\n",
       "      <td>29</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.298317</td>\n",
       "      <td>6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.919630</td>\n",
       "      <td>-77.031189</td>\n",
       "      <td>13</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.595120</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42.339194</td>\n",
       "      <td>-71.049672</td>\n",
       "      <td>12</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    log_price  accommodates  bathrooms  host_identity_verified  \\\n",
       "1    5.129899             7        1.0                       0   \n",
       "2    4.976734             5        1.0                       1   \n",
       "4    4.744932             2        1.0                       1   \n",
       "5    4.442651             2        1.0                       1   \n",
       "7    4.787492             2        1.0                       1   \n",
       "8    4.787492             2        1.0                       0   \n",
       "10   4.605170             2        1.0                       1   \n",
       "11   5.010635             4        1.5                       1   \n",
       "13   5.298317             6        1.5                       1   \n",
       "17   4.595120             2        2.0                       1   \n",
       "\n",
       "    instant_bookable   latitude   longitude  number_of_reviews  \\\n",
       "1                  1  40.766115  -73.989040                  6   \n",
       "2                  1  40.808110  -73.943756                 10   \n",
       "4                  1  38.925627  -77.034596                  4   \n",
       "5                  1  37.753164 -122.429526                  3   \n",
       "7                  0  34.046737 -118.260439                  9   \n",
       "8                  0  37.781128 -122.501095                100   \n",
       "10                 0  40.723883  -73.983880                 82   \n",
       "11                 0  33.875862 -118.403293                 29   \n",
       "13                 1  38.919630  -77.031189                 13   \n",
       "17                 0  42.339194  -71.049672                 12   \n",
       "\n",
       "    review_scores_rating  bedrooms  ...  property_type_Serviced apartment  \\\n",
       "1                   93.0       3.0  ...                                 0   \n",
       "2                   92.0       1.0  ...                                 0   \n",
       "4                   80.0       0.0  ...                                 0   \n",
       "5                  100.0       1.0  ...                                 0   \n",
       "7                   93.0       1.0  ...                                 0   \n",
       "8                   99.0       1.0  ...                                 0   \n",
       "10                  93.0       1.0  ...                                 0   \n",
       "11                  97.0       2.0  ...                                 0   \n",
       "13                  89.0       2.0  ...                                 0   \n",
       "17                  88.0       1.0  ...                                 0   \n",
       "\n",
       "    property_type_Tent  property_type_Timeshare  property_type_Tipi  \\\n",
       "1                    0                        0                   0   \n",
       "2                    0                        0                   0   \n",
       "4                    0                        0                   0   \n",
       "5                    0                        0                   0   \n",
       "7                    0                        0                   0   \n",
       "8                    0                        0                   0   \n",
       "10                   0                        0                   0   \n",
       "11                   0                        0                   0   \n",
       "13                   0                        0                   0   \n",
       "17                   0                        0                   0   \n",
       "\n",
       "    property_type_Townhouse  property_type_Train  property_type_Treehouse  \\\n",
       "1                         0                    0                        0   \n",
       "2                         0                    0                        0   \n",
       "4                         0                    0                        0   \n",
       "5                         0                    0                        0   \n",
       "7                         0                    0                        0   \n",
       "8                         0                    0                        0   \n",
       "10                        0                    0                        0   \n",
       "11                        0                    0                        0   \n",
       "13                        0                    0                        0   \n",
       "17                        1                    0                        0   \n",
       "\n",
       "    property_type_Vacation home  property_type_Villa  property_type_Yurt  \n",
       "1                             0                    0                   0  \n",
       "2                             0                    0                   0  \n",
       "4                             0                    0                   0  \n",
       "5                             0                    0                   0  \n",
       "7                             0                    0                   0  \n",
       "8                             0                    0                   0  \n",
       "10                            0                    0                   0  \n",
       "11                            0                    0                   0  \n",
       "13                            0                    0                   0  \n",
       "17                            0                    0                   0  \n",
       "\n",
       "[10 rows x 56 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding categorical variables and dropping columns that are not used\n",
    "oneHotCols=[\"room_type\",\"bed_type\",\"city\",\"cancellation_policy\", \"property_type\"]\n",
    "pdata_reg.drop(['description','host_response_rate','first_review','host_since', 'zipcode','last_review','id','neighbourhood','cleaning_fee','host_has_profile_pic'], axis=1, inplace=True)\n",
    "pdata_reg=pd.get_dummies(pdata_reg, columns=oneHotCols,drop_first=True)\n",
    "pdata_reg.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nP7EuWLx-HPC"
   },
   "source": [
    "##### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6AoYD8G-HPC"
   },
   "source": [
    "We went with an 80:20 train:test split of the data providing 80% of the data into a training set for teaching the model and 20% of the data into a test set for testing how well the model performs at predicting the property type.\n",
    "\n",
    "We also decided to scale the data using the training data set. This helped our model since we had attributes in a variety of scales in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "frpRdqONtBM1",
    "outputId": "ba2dc643-d961-41d7-9d89-d920a8b5993d"
   },
   "outputs": [],
   "source": [
    "# create variables we are more familiar with\n",
    "X_cls = pdata_cls.drop('property_type',axis=1).values     \n",
    "y_cls = pdata_cls['property_type'].values\n",
    "\n",
    "yhat_cls = np.zeros(y_cls.shape) # we will fill this with predictions\n",
    "scl_cls = StandardScaler()\n",
    "X_scaled_cls = scl_cls.fit_transform(X_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43320 entries, 1 to 74110\n",
      "Data columns (total 56 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   log_price                            43320 non-null  float64\n",
      " 1   accommodates                         43320 non-null  int64  \n",
      " 2   bathrooms                            43320 non-null  float64\n",
      " 3   host_identity_verified               43320 non-null  int64  \n",
      " 4   instant_bookable                     43320 non-null  int64  \n",
      " 5   latitude                             43320 non-null  float64\n",
      " 6   longitude                            43320 non-null  float64\n",
      " 7   number_of_reviews                    43320 non-null  int64  \n",
      " 8   review_scores_rating                 43320 non-null  float64\n",
      " 9   bedrooms                             43320 non-null  float64\n",
      " 10  beds                                 43320 non-null  float64\n",
      " 11  room_type_Private room               43320 non-null  uint8  \n",
      " 12  room_type_Shared room                43320 non-null  uint8  \n",
      " 13  bed_type_Couch                       43320 non-null  uint8  \n",
      " 14  bed_type_Futon                       43320 non-null  uint8  \n",
      " 15  bed_type_Pull-out Sofa               43320 non-null  uint8  \n",
      " 16  bed_type_Real Bed                    43320 non-null  uint8  \n",
      " 17  city_Chicago                         43320 non-null  uint8  \n",
      " 18  city_DC                              43320 non-null  uint8  \n",
      " 19  city_LA                              43320 non-null  uint8  \n",
      " 20  city_NYC                             43320 non-null  uint8  \n",
      " 21  city_SF                              43320 non-null  uint8  \n",
      " 22  cancellation_policy_moderate         43320 non-null  uint8  \n",
      " 23  cancellation_policy_strict           43320 non-null  uint8  \n",
      " 24  cancellation_policy_super_strict_30  43320 non-null  uint8  \n",
      " 25  cancellation_policy_super_strict_60  43320 non-null  uint8  \n",
      " 26  property_type_Bed & Breakfast        43320 non-null  uint8  \n",
      " 27  property_type_Boat                   43320 non-null  uint8  \n",
      " 28  property_type_Boutique hotel         43320 non-null  uint8  \n",
      " 29  property_type_Bungalow               43320 non-null  uint8  \n",
      " 30  property_type_Cabin                  43320 non-null  uint8  \n",
      " 31  property_type_Camper/RV              43320 non-null  uint8  \n",
      " 32  property_type_Castle                 43320 non-null  uint8  \n",
      " 33  property_type_Cave                   43320 non-null  uint8  \n",
      " 34  property_type_Chalet                 43320 non-null  uint8  \n",
      " 35  property_type_Condominium            43320 non-null  uint8  \n",
      " 36  property_type_Dorm                   43320 non-null  uint8  \n",
      " 37  property_type_Earth House            43320 non-null  uint8  \n",
      " 38  property_type_Guest suite            43320 non-null  uint8  \n",
      " 39  property_type_Guesthouse             43320 non-null  uint8  \n",
      " 40  property_type_Hostel                 43320 non-null  uint8  \n",
      " 41  property_type_House                  43320 non-null  uint8  \n",
      " 42  property_type_Hut                    43320 non-null  uint8  \n",
      " 43  property_type_In-law                 43320 non-null  uint8  \n",
      " 44  property_type_Loft                   43320 non-null  uint8  \n",
      " 45  property_type_Other                  43320 non-null  uint8  \n",
      " 46  property_type_Serviced apartment     43320 non-null  uint8  \n",
      " 47  property_type_Tent                   43320 non-null  uint8  \n",
      " 48  property_type_Timeshare              43320 non-null  uint8  \n",
      " 49  property_type_Tipi                   43320 non-null  uint8  \n",
      " 50  property_type_Townhouse              43320 non-null  uint8  \n",
      " 51  property_type_Train                  43320 non-null  uint8  \n",
      " 52  property_type_Treehouse              43320 non-null  uint8  \n",
      " 53  property_type_Vacation home          43320 non-null  uint8  \n",
      " 54  property_type_Villa                  43320 non-null  uint8  \n",
      " 55  property_type_Yurt                   43320 non-null  uint8  \n",
      "dtypes: float64(7), int64(4), uint8(45)\n",
      "memory usage: 5.8 MB\n"
     ]
    }
   ],
   "source": [
    "pdata_reg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create regression x and y \n",
    "X_reg = pdata_reg.drop('log_price',axis=1).values     \n",
    "y_reg = pdata_reg['log_price'].values\n",
    "\n",
    "yhat_reg = np.zeros(y_reg.shape) # we will fill this with predictions\n",
    "scl_reg = StandardScaler()\n",
    "X_scaled_reg = scl_reg.fit_transform(X_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.12989872 4.97673374 4.74493213 ... 5.04342512 5.22035583 4.85203026]\n"
     ]
    }
   ],
   "source": [
    "print(y_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Describing the Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42775 entries, 1 to 74110\n",
      "Data columns (total 26 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   log_price                            42775 non-null  float64\n",
      " 1   property_type                        42775 non-null  int64  \n",
      " 2   accommodates                         42775 non-null  int64  \n",
      " 3   bathrooms                            42775 non-null  float64\n",
      " 4   host_identity_verified               42775 non-null  int64  \n",
      " 5   instant_bookable                     42775 non-null  int64  \n",
      " 6   number_of_reviews                    42775 non-null  int64  \n",
      " 7   review_scores_rating                 42775 non-null  float64\n",
      " 8   bedrooms                             42775 non-null  float64\n",
      " 9   beds                                 42775 non-null  float64\n",
      " 10  room_type_Private room               42775 non-null  uint8  \n",
      " 11  room_type_Shared room                42775 non-null  uint8  \n",
      " 12  bed_type_Couch                       42775 non-null  uint8  \n",
      " 13  bed_type_Futon                       42775 non-null  uint8  \n",
      " 14  bed_type_Pull-out Sofa               42775 non-null  uint8  \n",
      " 15  bed_type_Real Bed                    42775 non-null  uint8  \n",
      " 16  city_Chicago                         42775 non-null  uint8  \n",
      " 17  city_DC                              42775 non-null  uint8  \n",
      " 18  city_LA                              42775 non-null  uint8  \n",
      " 19  city_NYC                             42775 non-null  uint8  \n",
      " 20  city_SF                              42775 non-null  uint8  \n",
      " 21  cancellation_policy_moderate         42775 non-null  uint8  \n",
      " 22  cancellation_policy_strict           42775 non-null  uint8  \n",
      " 23  cancellation_policy_super_strict_30  42775 non-null  uint8  \n",
      " 24  cancellation_policy_super_strict_60  42775 non-null  uint8  \n",
      " 25  region_East                          42775 non-null  uint8  \n",
      "dtypes: float64(5), int64(5), uint8(16)\n",
      "memory usage: 4.2 MB\n"
     ]
    }
   ],
   "source": [
    "pdata_cls.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43320 entries, 1 to 74110\n",
      "Data columns (total 56 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   log_price                            43320 non-null  float64\n",
      " 1   accommodates                         43320 non-null  int64  \n",
      " 2   bathrooms                            43320 non-null  float64\n",
      " 3   host_identity_verified               43320 non-null  int64  \n",
      " 4   instant_bookable                     43320 non-null  int64  \n",
      " 5   latitude                             43320 non-null  float64\n",
      " 6   longitude                            43320 non-null  float64\n",
      " 7   number_of_reviews                    43320 non-null  int64  \n",
      " 8   review_scores_rating                 43320 non-null  float64\n",
      " 9   bedrooms                             43320 non-null  float64\n",
      " 10  beds                                 43320 non-null  float64\n",
      " 11  room_type_Private room               43320 non-null  uint8  \n",
      " 12  room_type_Shared room                43320 non-null  uint8  \n",
      " 13  bed_type_Couch                       43320 non-null  uint8  \n",
      " 14  bed_type_Futon                       43320 non-null  uint8  \n",
      " 15  bed_type_Pull-out Sofa               43320 non-null  uint8  \n",
      " 16  bed_type_Real Bed                    43320 non-null  uint8  \n",
      " 17  city_Chicago                         43320 non-null  uint8  \n",
      " 18  city_DC                              43320 non-null  uint8  \n",
      " 19  city_LA                              43320 non-null  uint8  \n",
      " 20  city_NYC                             43320 non-null  uint8  \n",
      " 21  city_SF                              43320 non-null  uint8  \n",
      " 22  cancellation_policy_moderate         43320 non-null  uint8  \n",
      " 23  cancellation_policy_strict           43320 non-null  uint8  \n",
      " 24  cancellation_policy_super_strict_30  43320 non-null  uint8  \n",
      " 25  cancellation_policy_super_strict_60  43320 non-null  uint8  \n",
      " 26  property_type_Bed & Breakfast        43320 non-null  uint8  \n",
      " 27  property_type_Boat                   43320 non-null  uint8  \n",
      " 28  property_type_Boutique hotel         43320 non-null  uint8  \n",
      " 29  property_type_Bungalow               43320 non-null  uint8  \n",
      " 30  property_type_Cabin                  43320 non-null  uint8  \n",
      " 31  property_type_Camper/RV              43320 non-null  uint8  \n",
      " 32  property_type_Castle                 43320 non-null  uint8  \n",
      " 33  property_type_Cave                   43320 non-null  uint8  \n",
      " 34  property_type_Chalet                 43320 non-null  uint8  \n",
      " 35  property_type_Condominium            43320 non-null  uint8  \n",
      " 36  property_type_Dorm                   43320 non-null  uint8  \n",
      " 37  property_type_Earth House            43320 non-null  uint8  \n",
      " 38  property_type_Guest suite            43320 non-null  uint8  \n",
      " 39  property_type_Guesthouse             43320 non-null  uint8  \n",
      " 40  property_type_Hostel                 43320 non-null  uint8  \n",
      " 41  property_type_House                  43320 non-null  uint8  \n",
      " 42  property_type_Hut                    43320 non-null  uint8  \n",
      " 43  property_type_In-law                 43320 non-null  uint8  \n",
      " 44  property_type_Loft                   43320 non-null  uint8  \n",
      " 45  property_type_Other                  43320 non-null  uint8  \n",
      " 46  property_type_Serviced apartment     43320 non-null  uint8  \n",
      " 47  property_type_Tent                   43320 non-null  uint8  \n",
      " 48  property_type_Timeshare              43320 non-null  uint8  \n",
      " 49  property_type_Tipi                   43320 non-null  uint8  \n",
      " 50  property_type_Townhouse              43320 non-null  uint8  \n",
      " 51  property_type_Train                  43320 non-null  uint8  \n",
      " 52  property_type_Treehouse              43320 non-null  uint8  \n",
      " 53  property_type_Vacation home          43320 non-null  uint8  \n",
      " 54  property_type_Villa                  43320 non-null  uint8  \n",
      " 55  property_type_Yurt                   43320 non-null  uint8  \n",
      "dtypes: float64(7), int64(4), uint8(45)\n",
      "memory usage: 5.8 MB\n"
     ]
    }
   ],
   "source": [
    "pdata_reg.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Q4yavGMzUjw"
   },
   "source": [
    "### **Modeling and Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation Metrics Described (Classification / Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use mean absolute error (MAE) to score the regression models created \n",
    "#(the scale of MAE is identical to the response variable)\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "\n",
    "#Function for Root mean squared error\n",
    "#https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "def rmse(y_actual, y_predicted):\n",
    "    return np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "\n",
    "#Function for Mean Absolute Percentage Error (MAPE) - Untested\n",
    "#Adapted from - https://stackoverflow.com/questions/42250958/how-to-optimize-mape-code-in-python\n",
    "def mape(y_actual, y_predicted): \n",
    "    mask = y_actual != 0\n",
    "    return (np.fabs(y_actual - y_predicted)/y_actual)[mask].mean() * 100\n",
    "\n",
    "#Create scorers for rmse and mape functions\n",
    "mae_scorer = make_scorer(score_func=mean_absolute_error, greater_is_better=False)\n",
    "rmse_scorer = make_scorer(score_func=rmse, greater_is_better=False)\n",
    "mape_scorer = make_scorer(score_func=mape, greater_is_better=False)\n",
    "\n",
    "#Make scorer array to pass into cross_validate() function for producing mutiple scores for each cv fold.\n",
    "errorScoring = {'MAE':  mae_scorer, \n",
    "                'RMSE': rmse_scorer,\n",
    "                'MAPE': mape_scorer\n",
    "               } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "499XZPuo-HO-"
   },
   "source": [
    "#### Task One: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "#KNN\n",
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method for splitting Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cross validation iterator\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size = 0.2, train_size = 0.8)\n",
    "\n",
    "# now iterate through and get predictions, saved to the correct row in yhat\n",
    "# NOTE: you can parallelize this using the cross_val_predict method\n",
    "# fill in the training and testing data and save as separate variables\n",
    "for trainidx, testidx in cv.split(X_scaled_cls,y_cls):\n",
    "    # note that these are sparse matrices\n",
    "    X_train_scaled_cls = X_scaled_cls[trainidx]\n",
    "    X_test_scaled_cls = X_scaled_cls[testidx]\n",
    "    y_train_cls = y_cls[trainidx]\n",
    "    y_test_cls = y_cls[testidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_C7avMrtBM2",
    "outputId": "afc5a8b4-80f0-4679-c0f4-db2f409b4519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.00% data is in training set\n",
      "20.00% data is in test set\n"
     ]
    }
   ],
   "source": [
    "#verifying the test vs train split\n",
    "print(\"{0:0.2f}% data is in training set\".format((len(X_train_scaled_cls)/len(pdata_cls.index)) * 100))\n",
    "print(\"{0:0.2f}% data is in test set\".format((len(X_test_scaled_cls)/len(pdata_cls.index)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task Two: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LASSO\n",
    "#Random Forest\n",
    "#Need another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=3, test_size = 0.1, train_size = 0.2)\n",
    "\n",
    "for train, test in hypercv.split(X_scaled_reg,y_reg):\n",
    "    # note that these are sparse matrices\n",
    "    X_train_scaled_reg = X_scaled_reg[trainidx]\n",
    "    X_test_scaled_reg = X_scaled_reg[testidx]\n",
    "    y_train_reg = y_reg[trainidx]\n",
    "    y_test_reg = y_reg[testidx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def EvaluateRegressionEstimator(regEstimator, X, y, cv):\n",
    "    \n",
    "    scores = cross_validate(regEstimator, X, y, scoring=errorScoring, cv=cv, return_train_score=True)\n",
    "\n",
    "    #cross val score sign-flips the outputs of MAE\n",
    "    # https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "    scores['test_MAE'] = scores['test_MAE'] * -1\n",
    "    scores['test_MAPE'] = scores['test_MAPE'] * -1\n",
    "    scores['test_RMSE'] = scores['test_RMSE'] * -1\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    maeAvg = scores['test_MAE'].mean()\n",
    "    print_str = \"The average MAE for all cv folds is: \\t\\t\\t {maeAvg:.5}\"\n",
    "    print(print_str.format(maeAvg=maeAvg))\n",
    "\n",
    "    #print mean test_MAPE for all folds\n",
    "    scores['test_MAPE'] = scores['test_MAPE']\n",
    "    mape_avg = scores['test_MAPE'].mean()\n",
    "    print_str = \"The average MAE percentage (MAPE) for all cv folds is: \\t {mape_avg:.5}\"\n",
    "    print(print_str.format(mape_avg=mape_avg))\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    RMSEavg = scores['test_RMSE'].mean()\n",
    "    print_str = \"The average RMSE for all cv folds is: \\t\\t\\t {RMSEavg:.5}\"\n",
    "    print(print_str.format(RMSEavg=RMSEavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['MAE'] = scores['test_MAE']\n",
    "    scoresResults['MAPE'] = scores['test_MAPE']\n",
    "    scoresResults['RMSE'] = scores['test_RMSE']\n",
    "    return scoresResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done  22 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=14)]: Done 162 out of 162 | elapsed: 78.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=None, test_size=0.1, train_size=0.2),\n",
       "             estimator=RandomForestRegressor(), n_jobs=14,\n",
       "             param_grid={'criterion': ['mae'], 'min_samples_leaf': [1, 5, 10],\n",
       "                         'min_samples_split': [5, 10, 15],\n",
       "                         'n_estimators': [5, 10, 20, 50, 100, 500],\n",
       "                         'n_jobs': [14], 'random_state': [0]},\n",
       "             scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sklearn.ensemble import RandomForestRegressor\n",
    ">>> from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "\n",
    "mae_scorer = make_scorer(score_func=mean_absolute_error, greater_is_better=False)\n",
    "#rmse_scorer = mean_squared_error(score_func=rmse, greater_is_better=False)\n",
    "#mape_scorer = mean_absolute_error(score_func=mape, greater_is_better=False)\n",
    "\n",
    "linreg = RandomForestRegressor()\n",
    "parameters = {'min_samples_split':[5,10,15],\n",
    "             'n_estimators':[5,10,20,50,100,500],\n",
    "             'min_samples_leaf':[1,5,10],\n",
    "             'criterion':['mae'],\n",
    "             'n_jobs':[14],\n",
    "             'random_state':[0]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=linreg\n",
    "                            , n_jobs=14\n",
    "                            , verbose=1\n",
    "                            ,param_grid=parameters\n",
    "                            ,cv=cv\n",
    "                            ,scoring=mae_scorer)\n",
    "\n",
    "regGridSearch.fit(X_train_scaled_reg, y_train_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(criterion='mae', min_samples_split=5, n_estimators=500,\n",
       "                      n_jobs=14, random_state=0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cross validation iterator\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=10, test_size = 0.2, train_size = 0.8)\n",
    "\n",
    "# now iterate through and get predictions, saved to the correct row in yhat\n",
    "# NOTE: you can parallelize this using the cross_val_predict method\n",
    "# fill in the training and testing data and save as separate variables\n",
    "for trainidx, testidx in cv.split(X_scaled_reg,y_reg):\n",
    "    # note that these are sparse matrices\n",
    "    X_train_scaled_reg = X_scaled_reg[trainidx]\n",
    "    X_test_scaled_reg = X_scaled_reg[testidx]\n",
    "    y_train_reg = y_reg[trainidx]\n",
    "    y_test_reg = y_reg[testidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.00% data is in training set\n",
      "20.00% data is in test set\n"
     ]
    }
   ],
   "source": [
    "#verifying the test vs train split\n",
    "print(\"{0:0.2f}% data is in training set\".format((len(X_train_scaled_reg)/len(pdata_reg.index)) * 100))\n",
    "print(\"{0:0.2f}% data is in test set\".format((len(X_test_scaled_reg)/len(pdata_reg.index)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.ensemble import RandomForestRegressor\n",
    ">>> from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "\n",
    "regEstimator = RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None, max_features='auto',\n",
    "                                    max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                    min_samples_leaf=10, min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
    "                                    n_estimators=500, n_jobs=14, oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "EvaluateRegressionEstimator(regEstimator, X_train_scaled_reg, y_train_reg, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Lab Work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuvPeLvm-HPD"
   },
   "source": [
    "##### Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaWV-CRw-HPD"
   },
   "source": [
    "We ran a grid search using a penalty of l2, using 10 fold cross-validation, and proceeded to test which type of solver, C value and max_iterations would be best suited for our data.\n",
    "\n",
    "We found that a liblinear solver performed best with our specific data, using the accuracy metric and decided to use it in our Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZ3cIueUtBM6"
   },
   "outputs": [],
   "source": [
    "#run a grid search to evaluate the parameters as part of hyperparameter tuning\n",
    "modelGRID = LogisticRegression()\n",
    "\n",
    "parameters = {'penalty': ['l2'],\n",
    "             'C': [.001,.75,10],\n",
    "             'solver': ['newton-cg','liblinear','sag','saga'],\n",
    "              'max_iter':[100,500]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "linQ84S1tBM6",
    "outputId": "2a52ba80-82ca-4c40-e13c-08d9348fb059"
   },
   "outputs": [],
   "source": [
    "#identify the best parameters as determined by our grid search accuracy results\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(modelGRID,n_jobs=25,param_grid=parameters,cv=10,scoring='accuracy')\n",
    "gs.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uk6xu10GX4lV",
    "outputId": "3d47aa2e-f410-4afd-93f7-565cbe2065d6"
   },
   "outputs": [],
   "source": [
    "#mean test score values associated with each grid search parameter combination \n",
    "params = gs.cv_results_['params']\n",
    "result = gs.cv_results_['mean_test_score']\n",
    "for params,result in zip(params, result):\n",
    "    print(params, 'has an accuracy of', round(result,ndigits=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byKlO3KKXZUa",
    "outputId": "186edfa6-aecb-4389-e557-d0e4edfc883a"
   },
   "outputs": [],
   "source": [
    "#parameter combination with the highest score\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKO5kHuM-HPE"
   },
   "source": [
    "### **Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEWqvEnf-HPF"
   },
   "source": [
    "With our optimized parameters in place, we trained our model using the training data set.\n",
    "\n",
    "We then predicted the property types we would expect to see using our test variables.\n",
    "\n",
    "We finally compared our true response variables from the test data with our y predicted variables and calculated the accuracy of that prediction.\n",
    "\n",
    "Our accuracy ended up being 73.6% overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDH9wIHItBM3",
    "outputId": "ee1819d2-2662-4ab7-f451-613ac96d2aaa"
   },
   "outputs": [],
   "source": [
    "# Fit the model on train\n",
    "modelFINAL = LogisticRegression(random_state=42,penalty='l2', C = 0.001,solver='liblinear', max_iter=100)\n",
    "modelFINAL.fit(X_train_scaled, y_train)\n",
    "#predict on test\n",
    "y_predict = modelFINAL.predict(X_test_scaled)\n",
    "model_score = round(mt.accuracy_score(y_test,y_predict),ndigits=3)\n",
    "print(model_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhS8JkJXtBM4",
    "outputId": "42edaffa-a8e0-4961-9168-934ba18e106a"
   },
   "outputs": [],
   "source": [
    "#parameters used in the final Logistic Regression Model\n",
    "modelFINAL.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLbqGosP-HPF"
   },
   "source": [
    "### Logistic Regression Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2VjZxhPgzOH"
   },
   "source": [
    "#### **Interpret Feature Importance**\n",
    "\n",
    "The larger the weight, the higher importance the feature is to the model, therefore enhancing our predictability for the property_type. The reference variable encompasses the categorical features of Entire home/apt (room_type), Airbed (bed_type), Boston (city), flexible cancellation_policy, and West region.\n",
    "\n",
    "Based on the coefficient values we see listed above, we can determine that room type = Private, with a coefficient of .41 has a singificant influence on the probability of a room being an apartment vs other.  Additionally, the number of bathrooms with a coefficient of .29 is also a significant factor in classifying the property type.\n",
    "\n",
    "On the contrary, if they have a bed type = futon or a pull-out sofa, with a coefficient of 0.01, will not carry as much weight in predicting a property type.\n",
    "\n",
    "The value of these coefficients make sense to us in the influence they carry in predicting the property type, as one would look at the city, room type and number of bathrooms as more indicative of what type of property it is.  Where bed type may not be strongly indicative of what type of property it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WI1VoySqtBM8",
    "outputId": "84323459-326e-4d70-d15e-5c625d13522e"
   },
   "outputs": [],
   "source": [
    "#coefficient output based on in-class example\n",
    "weights = modelFINAL.coef_.T\n",
    "variable_names = x_train.columns\n",
    "for coef,name in zip(weights, variable_names):\n",
    "    print(name, 'has weight of', round(coef[0],ndigits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNnHYMXZkRKB"
   },
   "source": [
    "#### Exceptional work, model performance interpretation\n",
    "\n",
    "Looking at the accuracy alone, we would assume the model performs quite well.  However, if we look at the precision, recall and F1 score for the non-apartment or \"other\" property type, we see the model does not perform as well as expected.  The large difference in F1 score between the property type = apartment vs property type = other, signals we should consider rebalancing our lower representative property types to fully leverage their predictive attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "oVcTwKH3tBM5",
    "outputId": "a0782117-d1be-40da-faec-5a387a23cca0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## function to get confusion matrix in a proper format\n",
    "def draw_cm( actual, predicted ):\n",
    "    cm = confusion_matrix( actual, predicted)\n",
    "    sns.heatmap(cm, annot=True,  fmt='.2f', xticklabels = [0,1] , yticklabels = [0,1] )\n",
    "    plt.ylabel('Observed')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Training accuracy\",round(modelFINAL.score(X_train_scaled,y_train),ndigits=3))\n",
    "print()\n",
    "print(\"Testing accuracy\",round(mt.accuracy_score(y_test, y_predict),ndigits=3))\n",
    "print()\n",
    "print('Confusion Matrix')\n",
    "print(draw_cm(y_test,y_predict))\n",
    "\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below is a visual representation of the logistic regression coefficient, as displayed on the chart having a value of NYC or being in the Eastern region of the united states reduces the odds of a property being an apartment vs other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "s7psrVoJNDKt",
    "outputId": "ef59c94f-d704-499b-9990-0f52bd5c4c71"
   },
   "outputs": [],
   "source": [
    "#coeffient plot\n",
    "\n",
    "from matplotlib import pyplot as pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "weights = pd.Series(modelFINAL.coef_[0],index=x_train.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CYNS38h-HPG"
   },
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAc3dWi7-HPK"
   },
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvCGyeBb-HPK"
   },
   "source": [
    "For our support vector machine model we applied a grid search function with 10 fold cross validation, to determine which parameters would perform best given our data.\n",
    "\n",
    "We found that using an alpha 0.01, using a hinge loss and providing a penalty of l2 is optimal for our classification task.\n",
    "\n",
    "Additionally, the stochastic gradient descent model performed more efficiently with regards to run time since our data was initially quite sparse given the number of columns in our grid due to one hot encoding the neighborhood category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1DvARD9btBM-",
    "outputId": "a72ea193-d320-4d4b-867f-6e99d207e991"
   },
   "outputs": [],
   "source": [
    "#https://michael-fuchs-python.netlify.app/2019/11/11/introduction-to-sgd-classifier/\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    \"loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\", \"perceptron\"],\n",
    "    \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"penalty\" : [\"l2\"],\n",
    "}\n",
    "clf = SGDClassifier()\n",
    "grid = GridSearchCV(clf, param_grid=params, cv=10)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d00HQ7FEmWYr"
   },
   "source": [
    "\n",
    "The plot below shows the perfomance of different loss metrics on our data and shows hinge perfoming best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "5AQOYZpB-JYf",
    "outputId": "81f18a8d-b6a8-4c64-db94-3f56ea12b2df"
   },
   "outputs": [],
   "source": [
    "losses = [\"hinge\", \"log\", \"modified_huber\", \"perceptron\", \"squared_hinge\"]\n",
    "scores = []\n",
    "for loss in losses:\n",
    "    clf = SGDClassifier(loss='hinge', penalty=\"l2\", alpha=0.01, max_iter=1000)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    scores.append(clf.score(X_test_scaled, y_test))\n",
    "plt.title(\"Effect of loss\")\n",
    "plt.xlabel(\"loss\")\n",
    "plt.ylabel(\"score\")\n",
    "x = np.arange(len(losses))\n",
    "plt.xticks(x, losses)\n",
    "plt.plot(x, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kL9wO39-HPM"
   },
   "source": [
    "##### Final Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgToM7Tm-HPM"
   },
   "source": [
    "After identifying the optimal parameters using the grid search function, we applied them to our final SVM Model.\n",
    "\n",
    "The model accuracy for our classification task is 73%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moDVUhXJtBM9",
    "outputId": "9fdab18a-d1d8-4090-a730-6f3bdce42aca"
   },
   "outputs": [],
   "source": [
    "svm_model = SGDClassifier(alpha= 0.01, loss= 'hinge', penalty='l2')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "grid_predictions = svm_model.predict(X_test_scaled)\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, grid_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxTcp5qim6qq",
    "outputId": "30ca69bf-f237-400c-c52d-fb8576efaf78"
   },
   "outputs": [],
   "source": [
    "#coefficient list based on class example\n",
    "weights = svm_model.coef_.T\n",
    "variable_names = x_train.columns\n",
    "for coef,name in zip(weights, variable_names):\n",
    "    print(name, 'has weight of', round(coef[0],ndigits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWL8cxeerXBk"
   },
   "source": [
    "### Exceptional work, model performance interpretation SVM\n",
    "\n",
    "Just like the accuracy in the Logistic Regression, we would assume the model performs quite well based on accuracy score alone. However, when we look at the precision, recall and F1 score for the non-apartment or \"other\" property type, we see the model does not perform as well as expected. \n",
    "\n",
    "Like the Logistic Regression model performance above, the large difference in F1 score between the property type = apartment vs property type = other, signals we should consider rebalancing our lower representative property types to fully leverage their predictive attributes.\n",
    "\n",
    "This is surprising given the difference in coefficient weights, since the coefficient values differ in weight, we would expect a different performance metrics from the SVM model results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "vjrTdGHRBCbY",
    "outputId": "b3759851-780b-4c48-db29-a8f47c150455"
   },
   "outputs": [],
   "source": [
    "print(draw_cm(y_test, grid_predictions))\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wZ-wbFR-HPN"
   },
   "source": [
    "### **Model Comparison and Model Advantages**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VgciIirDPJ9"
   },
   "source": [
    "To determine the best overall model, accuracy, precision, recall and their harmonized value of F1-score were considered as the core metrics. The Logistic Regression model had a slightly better performance based on the F1 score compared to Stochastic Gradient Descent Support Vector Machine model at 81% Vs 80% respectively.\n",
    "\n",
    "We started modeling the full dataset and the time and efficiency to run each model was quite high. Additionally, the number of unique values in the neighborhood data, which we considered an important attribute at the time made our data structure quite sparse.\n",
    "\n",
    "To have a better performance on both execution and training of the large amount of data, we moved from SVM to Stochastic Gradient Descent optimized SVM, which improved performance but still had quite a long run time.  We then removed neighborhood (removing the columns with too many values).This reduced the accuracy across all our models by 3%, reducing our accuracy from 76% to 73% but increased the speed and performance for both models.  Another approach would have been to sample the data but we would have to worry about balancing the classes as there are property types that are significantly under-represented in the data set.\n",
    "\n",
    "Overall the models performed quite similarly in our classification task, we would choose the Logistic Regression model due to the simplicity of the model and our ability to calculate the odds ratio given any set of attributes, predicting the likelihood of a certain classification. We consider the execution speed and interpretability of the Logistic Regression model to be a major advantage over the SVM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b35kd2PuYO8f"
   },
   "source": [
    "## **Interpret Support Vectors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nj013VXYLQy"
   },
   "source": [
    "Looking at the separation of the original data and the sepaation of the support vectors we see that the original data provides greater separation of the two. Likely this is due to our support vectors containing both correct and incorrect classifications. Recall that we had an overall accuracy of 73% for support vectors, however the recall barely provided 50% accuracy when classifying the Other property type. These misclassified values shrink the margin that SVC would create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cLIqq7U7v-q",
    "outputId": "e60823db-22fc-4518-ff15-37362f4c241e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "X = X.values\n",
    "Y = Y.values\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(Y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,test_size=0.2)\n",
    "print(cv_object)\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,Y):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = Y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = Y[test_indices] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqxY9u5RGz_k",
    "outputId": "0d912862-7b41-455e-c1e1-bc841506d704"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_chart_model = SVC()\n",
    "svm_chart_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "x6UQN-vfLQIZ",
    "outputId": "e64260b7-bfd4-41e7-d063-dd94bf5ade33"
   },
   "outputs": [],
   "source": [
    "#X_train = pd.DataFrame(X_train)\n",
    "df_tested_on = X_train.iloc[train_indices].copy() # saved from above, the indices chosen for training\n",
    "\n",
    "# now get the support vectors from the trained model\n",
    "df_support = df_tested_on.iloc[svm_chart_model.support_,:].copy()\n",
    "df_tested_on.head()\n",
    "\n",
    "variable_names = x_train.columns\n",
    "df_support.columns = variable_names\n",
    "df_support['property_type'] = y_train[svm_chart_model.support_] # add back in the 'Survived' Column to the pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 812
    },
    "id": "BO8Qp-04WA1U",
    "outputId": "1e2ba781-3248-4886-8760-63c0648ea90f"
   },
   "outputs": [],
   "source": [
    "#chart from class example\n",
    "from pandas.plotting import boxplot\n",
    "\n",
    "# group the original data and the support vectors\n",
    "df_grouped_support = df_support.groupby(['property_type'])\n",
    "df_grouped = pdata.groupby(['property_type'])\n",
    "\n",
    "# plot KDE of Different variables\n",
    "vars_to_plot = ['bedrooms','beds','bathrooms']\n",
    "\n",
    "for v in vars_to_plot:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    # plot support vector stats\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = df_grouped_support[v].plot.kde() \n",
    "    plt.legend(['Apartment','Other'])\n",
    "    plt.title(v+' (Instances chosen as Support Vectors)')\n",
    "    \n",
    "    # plot original distributions\n",
    "    plt.subplot(1,2,2)\n",
    "    ax = df_grouped[v].plot.kde() \n",
    "    plt.legend(['Apartment','Other'])\n",
    "    plt.title(v+' (Original)')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "Mini_Project_givemeanAPlus.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
